Задачей является разработка и наладка ИИ-ассистента для помощи в вопросах учебы и получения дополнитльного материала. LLM(Large Language Machine) как понятие о моделировании поведения и надстроек помощника-ассистента сыграет ключевую роль в реализации намеченых целей. Сниппет дальше по тексту. 
Из добавляемых фич -    1 .Веб страница, где каждый пользователь может пройти авторизацию и получить свои рекомендации от ИИ.
                        2. База данных, хранимая на сервере, доступ к БД имеет сервер, где развернут проект, в связи с региональными ограничениями нужно арендовать машину за рубежом.     
                        3. Улучшение структуры промптов, создание "развернутой инуструкции" к прочтению ИИ перед генерацией ответа.
#Пример: код за решеткой - комментирование кода, не участвует в отработке кода компилятором.
# By default, we Google Gemini Ключевая функция. В которую мы передаем запрос “промпт”, получаем ответ от ИИ
def call_llm(prompt: str, use_cache: bool = True) -> str:
    provider = get_llm_provider()
    if provider == "GEMINI":
        response_text = _call_llm_gemini(prompt)
    else:  # generic method using a URL that is OpenAI compatible API (Ollama, ...)
        response_text = _call_llm_provider(prompt)
    logger.info(f"RESPONSE: {response_text}")#Логирование запроса к ИИ
    return response_text


Получаем ответ в результате обработки запроса: текст, который мы получаем, работая, например с обычными языковыми моделями ИЛИ текст структурированный(здесь - .yaml), и
меющий иерархию, для более гибкого формирования следующих запросов к ИИ. Модель, которая была создана нами, работает на узлах “нодах”, узлы в свою очередь образуют пайплайн
мыслительных обработок "памяти предыдущих запросов". 

# Node 1 - AppriseStudentGrades - Results of person
# -------------------------------------------------------------------------------
class AssessStudentLevel(Node):
    """Описание работы, совершаемой узлом “”
    Node: AssessStudentLevel
    Purpose: Evaluate student's knowledge across subjects
    and generate a structured profile.
    """

    def prep(self, shared):
        student_data = shared["student_data"]  # dict from Database['data']
        use_cache = shared.get("use_cache", True)
        max_subjects = shared.get("max_subjects", 10)
        return student_data, use_cache, max_subjects

    def exec(self, prep_res):
        student_data, use_cache, max_subjects = prep_res
        print(f"Assessing knowledge level for {student_data.get('Full Name', 'Unknown')}...")
        prompt = f"""
You are an experienced school teacher AI. The data you received 
 contains school grades for subjects (highest score is 5), class number,
 and student biography.

Student Data:
{student_data}

For EACH subject (up to {max_subjects}):
1. Assign a knowledge level: Very Low, Average, Above Average, High.
2. Provide reasoning in 1-3 sentences.
3. Identify main strengths and gaps.

Output STRICTLY in YAML format:

```yaml
student_profile:		#Здесь мы явно задаем формат вывода-ответа от ИИ, чтобы 
  subjects:			    #ему же было проще продолжать работу.
    - name: ""
      level: ""
      reasoning: |
        ...
      strengths:
        - ""
      gaps:
        - ""
```"""

        response = call_llm(prompt, use_cache=(use_cache and self.cur_retry == 0))

        # --- Extract YAML safely ---#
        match = re.search(r"```yaml(.*?)```", response, re.DOTALL)
        if not match:
            raise ValueError("No YAML block found in LLM output")
        yaml_str = match.group(1).strip()

        profile = yaml.safe_load(yaml_str)
        if "student_profile" not in profile:
            raise ValueError("Missing 'student_profile' key in LLM output.")
        return profile

    def post(self, shared, prep_res, exec_res):
        shared["student_profile"] = exec_res
        print("Student profile stored in shared['student_profile'].")




В законченной работе мы прописали таких 5 нодов, финальный отвечает за формирование отчета(.html) в нашем случае

#Получаем ранее объявленные узлы
from nodes import (
    AssessStudentLevel,
    PrioritizeSubjects,
    KnowledgeToDiscover,
    FinalTeacherConclusion,
)

#А здесь пайплайн-последовательность, узлы занесены в переменные(в питоне переменные автоматически выбирают "структуру")
def create_teacher_flow():
    """Creates and returns the Teacher AI Agent flow."""
    assess_student = AssessStudentLevel(max_retries=3, wait=10)
    prioritize_subjects = PrioritizeSubjects(max_retries=3, wait=10)
    knowledge_to_discover = KnowledgeToDiscover(max_retries=3, wait=10)
    final_conclusion = FinalTeacherConclusion()
    # Connect nodes
    assess_student >> prioritize_subjects
    prioritize_subjects >> knowledge_to_discover
    knowledge_to_discover >> final_conclusion
    # Create flow
    teacher_flow = Flow(start=assess_student)

    return teacher_flow

